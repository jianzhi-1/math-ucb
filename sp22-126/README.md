# EECS 126
### Probability and Random Processes
UC Berkeley Spring 2022, taught by Prof Kannan Ramchandran

- [x] Week 1: Introduction (lec1); Probability Review (lec2)
- [x] Week 2: Distributions (lec3, lec4)
- [x] Week 3:
- [x] Week 4: ; Moment Generating Functions (lec8)
- [x] Week 5: Convergence (lec9);
- [x] Week 6: Midterm 1; Information Theory (lec11)
- [x] Week 7: Capacity (lec12); Discrete-Time Markov Chain (lec13)
- [x] Week 8: First Equations (lec14), Classification of Markov Chains (lec15)
- [x] Week 9: Poisson Processes (lec16); Splitting & Merging, Random Incidence Paradox (lec17)
- [x] Week 10: üçÉ Spring Break üçÉ
- [ ] Week 11:
- [ ] Week 12:
- [ ] Week 13:
- [ ] Week 14:
- [ ] Week 15:


### Lab Hacks

##### Numpy Functions
```python3
np.sum(x, axis=1) # sum over rows
np.random.rand(x, y) # generate a random matrix of dimensions x x y in the range [0, 1]
np.count_nonzero(x, axis=1) # count the number of nonzero elements over rows
np.add(x, y)
np.square(x)
np.less_equal(x, 1)
np.random.rand() # generates a random number from 0 to 1
np.random.randint(x) # generates a random integer from [0, x) (note x is exclusive)
np.random.randint(x, size=(3, 5))
np.unique(x)

def contains_duplicates(X):
  return len(np.unique(X)) != len(X)

### Matrix multiplication
return S@A

```

##### Random
```python3
from numpy import random
print(random.rand())
print(random.rand(5))
print(random.rand(3, 3))

random.sample(range(self.num_chunks), n_of_chunks)
```

##### Plotting
```python3
plt.figure() # new figure to plot on
plt.hist(x, range=[xminrange, xmaxrange], bins=np.arange(xminrange, xmaxrange, 1)) # histogram with fixed x range and bin interval
```

##### Commonplace
- Bernoulli
```python3
x = round(random.rand())
```
- Binomial(n, p)
```python3
binomial = random.binomial(n, p, num_trials)
```
##### Itertools
Python library that provides generator for permutations and combinations
```python3
import itertools
itertools.product(RANKS, SUITS)

a = [3, 1, 4, 5]
itertools.combination(a, n) # returns generator of all possible combinations of n-tuple of a
```

### Probability

##### Basics
- *ùîº\[Y] = ùîº\[ùîº\[Y|X]]*
- *Var\[Y]= Var\[ùîº\[Y|X]] + ùîº\[Var\[Y|X]]*

##### Convergence and Borel Cantelli Lemmas
- \[Convergence in probability] Let *(Y<sub>n</sub>)<sub>n</sub>* be a sequence of random variables (not necessarily independent) and *a ‚àà ‚Ñù*. Say *(Y<sub>n</sub>)<sub>n</sub>* converges to *a* in probability if *‚àÄŒµ > 0*, *lim<sub>n ‚Üí ‚àû</sub> ‚Ñô\[|Y<sub>n</sub> - a| ‚â• Œµ] = 0*.
- \[Convergence with probability 1] Let *(Y<sub>n</sub>)<sub>n</sub>* be a sequence of random variables (not necesarily independent) and *c ‚àà ‚Ñù*. Say *(Y<sub>n</sub>)<sub>n</sub>* converges to *c* in probability 1 (or **almost surely**) if *‚Ñô\[lim<sub>n ‚Üí ‚àû</sub>Y<sub>n</sub> = c] = 1*.
  - Equivalent definition: *‚Ñô\[œâ ‚àà Œ©: lim<sub>n ‚Üí ‚àû</sub> Y<sub>n</sub>(œâ) = Y(œâ)] = 1*
  - Equivalent definition: *‚àÄŒµ > 0*, *‚Ñô\[lim sup \{œâ ‚àà Œ© : |X<sub>n</sub>(œâ) - X(œâ)| > Œµ\}] = 0*
  - This is the same as pointwise convergence in MATH 104.
  - Implies convergence in probability by Fatou's lemma.
- Convergence with probability 1 implies convergence in probability.

- \[Borel Cantelli Lemma 1] Let *(A<sub>n</sub>)<sub>n</sub>* be a sequence of events such that *Œ£‚Ñô\[Y<sub>n</sub>] < ‚àû*. Then *‚Ñô\[\{A<sub>n</sub> infinitely often}] = 0*. i.e. the set of outcomes where *A<sub>n</sub>* happens infinitely often has measure *0*.
- \[Borel Cantelli Lemma 2]
- \[Continuity of Probability]

##### Law of Large Numbers

##### Transforms

##### Central Limit Theorem

### Random Processes

##### Discrete-Time Markov Chains

##### Information Theory
###### Entropy
Discrete 
*H(X) = -Œ£<sub>i</sub> ‚Ñô\[X = x<sub>i</sub>] log ‚Ñô\[X = x<sub>i</sub>]*

### MLE, MAP
##### Maximum Likelihood Estimation
*Œò<sub>MLE</sub> = argmax<sub>Œò</sub> ‚Ñô\[X|Œò]*

##### Maximum A Posteriori
*Œò<sub>MAP</sub> = argmax<sub>Œò</sub> ‚Ñô\[X|Œò]‚Ñô\[Œò]*

##### Estimation

### Applications

##### Binary Symmetric/Erasure Channel
*p* is the probability of error. *1 - p* is the probability of no error.
pg 119 Walrand

##### LLSE, MMSE

##### Kalman Filtering, Tracking


### Exam Area

#### Midterm 1 Prep üò§
See my [Midterm 1 Sheet](https://github.com/jianzhi-1/math-ucb/blob/main/sp22-126/EECS126_Midterm1Sheet.pdf)
- [x] 21 Fall
- [x] 21 Spring
- [x] 20 Fall
- [x] 20 Spring
- [x] 19 Fall
- [x] 19 Spring
- [x] 18 Fall
- [x] 18 Spring
- [x] 17 Fall
- [x] 14 Fall

#### Midterm 2 Prep üò§
- [ ] 21 Fall
- [ ] 21 Spring
- [ ] 20 Fall
- [x] 20 Spring
- [x] 19 Fall
- [x] 19 Spring
- [x] 18 Fall
- [x] 18 Spring
- [x] 17 Fall

#### Final Exam Prep üò§
- [ ] 21 Fall
- [ ] 21 Spring
- [ ] 20 Fall
- [ ] 20 Spring
- [ ] 19 Fall
- [ ] 19 Spring
- [ ] 18 Fall
- [ ] 18 Spring
- [ ] 17 Fall
